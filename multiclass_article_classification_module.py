# -*- coding: utf-8 -*-
"""Multiclass_Article_Classification_module.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15gxOiovTXY74OoGZbGr_500sO9cvuQWN

IMPORT NECESSARY PACKAGES
"""

import matplotlib.pyplot as plt
from tensorflow.keras.layers import Embedding
from tensorflow.keras import Sequential, Input
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional

"""MODEL DEVELOPMENT"""

class ModelDevelopment:
  def sequential_model(self, input_shape, vocab_size = 1000, out_dims = 128, 
                       nb_class=5, nb_node=128, dropout_rate=0.3):
    '''
      this is simple 3 LSTM layer deep learning model
      Parameters
      ----------
      input_shape : TYPE
            DESCRIPTION.
        nb_node : TYPE, optional
            DESCRIPTION. The default is 128.
        dropout_rate : TYPE, optional
            DESCRIPTION. The default is 0.3.
        output : TYPE, optional
            DESCRIPTION. The default is 1.
        Returns
        -------
        None.
    '''
    nlp = Sequential()
    nlp.add(Input(shape=(input_shape)))
    nlp.add(Embedding(vocab_size,out_dims))
    nlp.add(Bidirectional(LSTM(nb_node,return_sequences=(True))))
    nlp.add(Dropout(dropout_rate))
    nlp.add(Bidirectional(LSTM(nb_node)))
    nlp.add(Dropout(dropout_rate))
    nlp.add(Dense(nb_class, activation='softmax'))
    nlp.summary()

    return nlp

"""MODEL EVALUATION"""

class ModelEvaluation:
  def plot_hist_graph(self,hist):
    plt.figure()
    plt.plot(hist.history['loss'])
    plt.plot(hist.history['val_loss'])
    plt.legend(['Training Loss', 'Validation Loss'])
    plt.show()

    plt.figure()
    plt.plot(hist.history['acc'])
    plt.plot(hist.history['val_acc'])
    plt.legend(['Training Acc', 'Validation Acc'])
    plt.show()